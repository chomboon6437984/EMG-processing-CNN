{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5ba737b",
   "metadata": {},
   "source": [
    "## IMPORT libraly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "be08054f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import filtfilt, kaiserord, firwin, freqz, lfilter\n",
    "from scipy import stats, signal\n",
    "from pylab import figure, clf, plot, xlabel, ylabel, xlim, ylim, title, grid, axes, show\n",
    "from numpy import cos, sin, pi, absolute, arange\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514c5438",
   "metadata": {},
   "source": [
    "## Load train/val data and target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "27bdfdce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0713, 0.0768, 0.0821,  ..., 0.0538, 0.0513, 0.0501]],\n",
      "\n",
      "        [[0.1287, 0.1122, 0.0982,  ..., 0.1070, 0.1173, 0.1295]],\n",
      "\n",
      "        [[0.0507, 0.0557, 0.0609,  ..., 0.0628, 0.0576, 0.0553]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0529, 0.0410, 0.0326,  ..., 0.0806, 0.0822, 0.0834]],\n",
      "\n",
      "        [[0.0709, 0.0737, 0.0764,  ..., 0.0641, 0.0633, 0.0623]],\n",
      "\n",
      "        [[0.0538, 0.0508, 0.0478,  ..., 0.0845, 0.0838, 0.0849]]])\n",
      "torch.Size([40, 1, 64])\n",
      "tensor([[[0.0691, 0.0707, 0.0725,  ..., 0.0753, 0.0670, 0.0596]],\n",
      "\n",
      "        [[0.0447, 0.0422, 0.0408,  ..., 0.0520, 0.0564, 0.0611]],\n",
      "\n",
      "        [[0.0520, 0.0564, 0.0611,  ..., 0.0634, 0.0571, 0.0526]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0896, 0.0918, 0.0934,  ..., 0.3156, 0.3315, 0.3404]],\n",
      "\n",
      "        [[0.0448, 0.0487, 0.0543,  ..., 0.0654, 0.0624, 0.0600]],\n",
      "\n",
      "        [[0.0687, 0.0654, 0.0624,  ..., 0.0846, 0.0979, 0.1112]]])\n",
      "torch.Size([40, 1, 64])\n",
      "tensor([[[0.0423, 0.0462, 0.0526,  ..., 0.0324, 0.0322, 0.0323]],\n",
      "\n",
      "        [[0.0527, 0.0458, 0.0407,  ..., 0.0373, 0.0364, 0.0358]],\n",
      "\n",
      "        [[0.0359, 0.0362, 0.0367,  ..., 0.1031, 0.0972, 0.0913]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0545, 0.0560, 0.0570,  ..., 0.0388, 0.0467, 0.0556]],\n",
      "\n",
      "        [[0.0202, 0.0203, 0.0214,  ..., 0.0745, 0.0648, 0.0563]],\n",
      "\n",
      "        [[0.0853, 0.0745, 0.0648,  ..., 0.0518, 0.0518, 0.0516]]])\n",
      "torch.Size([18, 1, 64])\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/Users/Asus TUF/Desktop/data/train_set.csv')\n",
    "slice_D = data[['train_set']]\n",
    "slice_df = pd.DataFrame(data=slice_D)\n",
    "slice_df.columns = ['train_set']\n",
    "torch_train = torch.tensor(slice_df['train_set'].values)\n",
    "torch_train = torch_train.float()\n",
    "torch_train = torch.reshape(torch_train, (40, 1, 64))\n",
    "print(torch_train)\n",
    "print(torch_train.shape)\n",
    "\n",
    "data3 = pd.read_csv('/Users/Asus TUF/Desktop/data/valid_set.csv')\n",
    "valid_D = data3[['valid_set']]\n",
    "valid_df = pd.DataFrame(data=valid_D)\n",
    "valid_df.columns = ['valid_set']\n",
    "torch_valid = torch.tensor(valid_df['valid_set'].values)\n",
    "torch_valid = torch_valid.float()\n",
    "torch_valid = torch.reshape(torch_valid, (40, 1, 64))\n",
    "print(torch_valid)\n",
    "print(torch_valid.shape)\n",
    "\n",
    "data2 = pd.read_csv('/Users/Asus TUF/Desktop/data/test_data.csv')\n",
    "test_D = data2[['test_data']]\n",
    "test_df = pd.DataFrame(data=test_D)\n",
    "test_df.columns = ['test_data']\n",
    "torch_test = torch.tensor(test_df['test_data'].values)\n",
    "torch_test = torch_test.float()\n",
    "torch_test = torch.reshape(torch_test, (18, 1, 64))\n",
    "print(torch_test)\n",
    "print(torch_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b158e1f",
   "metadata": {},
   "source": [
    "## Load class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fb4b755b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
      "        1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0])\n",
      "torch.Size([40])\n",
      "tensor([1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0])\n",
      "torch.Size([18])\n"
     ]
    }
   ],
   "source": [
    "data4 = pd.read_csv('/Users/Asus TUF/Desktop/data/class_tr.csv')\n",
    "classtr_D = data4[['class_tr']]\n",
    "classtr_df = pd.DataFrame(data=classtr_D)\n",
    "classtr_df.columns = ['class_tr']\n",
    "class_trva = torch.tensor(classtr_df['class_tr'].values)\n",
    "print(class_trva)\n",
    "print(class_trva.shape)\n",
    "\n",
    "data5 = pd.read_csv('/Users/Asus TUF/Desktop/data/class_te.csv')\n",
    "classte_D = data5[['class_te']]\n",
    "classte_df = pd.DataFrame(data=classte_D)\n",
    "classte_df.columns = ['class_te']\n",
    "class_te = torch.tensor(classte_df['class_te'].values)\n",
    "print(class_te)\n",
    "print(class_te.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb50d05",
   "metadata": {},
   "source": [
    "## test convo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1625be14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 64, 8])\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# x2 = torch.randn(50,1,64)\n",
    "# conv = nn.Conv1d(1, 16, 3, padding=1)\n",
    "# conv2 = nn.Conv1d(16, 32, 3, padding=1)\n",
    "# conv3 = nn.Conv1d(32, 64, 3, padding=1)\n",
    "# m = nn.MaxPool1d(2, stride=2)\n",
    "# #y = torch.from_numpy(trainD)\n",
    "# x_con1 = conv(torch_train)\n",
    "# x_pool1 = m(x_con1)\n",
    "# x_con2 = conv2(x_pool1)\n",
    "# x_pool2 = m(x_con2)\n",
    "# x_con3 = conv3(x_pool2)\n",
    "# x_pool3 = m(x_con3)\n",
    "# print(x_pool3.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "83c05ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "trainD = torch_train \n",
    "trainV = torch_valid\n",
    "target = class_trva\n",
    "print(len(trainD))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf965922",
   "metadata": {},
   "source": [
    "## Create Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a7ddbf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv1d(1, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv2): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv3): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # convolutional layer (sees 64x1 1-D signal tensor)\n",
    "        self.conv1 = nn.Conv1d(1, 16, 3, padding=1)\n",
    "        # convolutional layer (sees 16x16x16 tensor)\n",
    "        self.conv2 = nn.Conv1d(16, 32, 3, padding=1)\n",
    "        # convolutional layer (sees 8x8x32 tensor)\n",
    "        self.conv3 = nn.Conv1d(32, 64, 3, padding=1)\n",
    "        # max pooling layer\n",
    "        self.pool = nn.MaxPool1d(2, 2)\n",
    "        # linear layer (64 * 4 * 4 -> 500)\n",
    "        self.fc1 = nn.Linear(64 * 8, 256)\n",
    "        # linear layer (500 -> 10)\n",
    "        self.fc2 = nn.Linear(256, 2)\n",
    "        # dropout layer (p=0.25)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # add sequence of convolutional and max pooling layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        # flatten image input\n",
    "        x = x.view(-1, 64 * 8)\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # add 1st hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # add 2nd hidden layer, with relu activation function\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# create a complete CNN\n",
    "model = Net()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "66edd576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# specify loss function (categorical cross-entropy)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# specify optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2374bf01",
   "metadata": {},
   "source": [
    "## Train Model and validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4e29094c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 5.124582 \tValidation Loss: 4.038838\n",
      "Validation loss decreased (inf --> 4.038838).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 3.932902 \tValidation Loss: 3.063720\n",
      "Validation loss decreased (4.038838 --> 3.063720).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 3.193080 \tValidation Loss: 2.397420\n",
      "Validation loss decreased (3.063720 --> 2.397420).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 2.651924 \tValidation Loss: 1.955165\n",
      "Validation loss decreased (2.397420 --> 1.955165).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 2.267624 \tValidation Loss: 1.537340\n",
      "Validation loss decreased (1.955165 --> 1.537340).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 1.875794 \tValidation Loss: 1.284744\n",
      "Validation loss decreased (1.537340 --> 1.284744).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.669447 \tValidation Loss: 1.100001\n",
      "Validation loss decreased (1.284744 --> 1.100001).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.439147 \tValidation Loss: 0.972375\n",
      "Validation loss decreased (1.100001 --> 0.972375).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.219383 \tValidation Loss: 0.789840\n",
      "Validation loss decreased (0.972375 --> 0.789840).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.113128 \tValidation Loss: 0.742897\n",
      "Validation loss decreased (0.789840 --> 0.742897).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.977583 \tValidation Loss: 0.635732\n",
      "Validation loss decreased (0.742897 --> 0.635732).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.912368 \tValidation Loss: 0.532070\n",
      "Validation loss decreased (0.635732 --> 0.532070).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.846360 \tValidation Loss: 0.469140\n",
      "Validation loss decreased (0.532070 --> 0.469140).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.745626 \tValidation Loss: 0.506138\n",
      "Epoch: 15 \tTraining Loss: 0.634249 \tValidation Loss: 0.402879\n",
      "Validation loss decreased (0.469140 --> 0.402879).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.666150 \tValidation Loss: 0.417480\n",
      "Epoch: 17 \tTraining Loss: 0.636321 \tValidation Loss: 0.365418\n",
      "Validation loss decreased (0.402879 --> 0.365418).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.556249 \tValidation Loss: 0.319633\n",
      "Validation loss decreased (0.365418 --> 0.319633).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.501248 \tValidation Loss: 0.261276\n",
      "Validation loss decreased (0.319633 --> 0.261276).  Saving model ...\n",
      "Epoch: 20 \tTraining Loss: 0.591696 \tValidation Loss: 0.314943\n",
      "Epoch: 21 \tTraining Loss: 0.449352 \tValidation Loss: 0.283729\n",
      "Epoch: 22 \tTraining Loss: 0.427044 \tValidation Loss: 0.193566\n",
      "Validation loss decreased (0.261276 --> 0.193566).  Saving model ...\n",
      "Epoch: 23 \tTraining Loss: 0.483526 \tValidation Loss: 0.322210\n",
      "Epoch: 24 \tTraining Loss: 0.418466 \tValidation Loss: 0.235644\n",
      "Epoch: 25 \tTraining Loss: 0.346237 \tValidation Loss: 0.214599\n",
      "Epoch: 26 \tTraining Loss: 0.343311 \tValidation Loss: 0.205586\n",
      "Epoch: 27 \tTraining Loss: 0.375843 \tValidation Loss: 0.192615\n",
      "Validation loss decreased (0.193566 --> 0.192615).  Saving model ...\n",
      "Epoch: 28 \tTraining Loss: 0.308342 \tValidation Loss: 0.175950\n",
      "Validation loss decreased (0.192615 --> 0.175950).  Saving model ...\n",
      "Epoch: 29 \tTraining Loss: 0.334761 \tValidation Loss: 0.191456\n",
      "Epoch: 30 \tTraining Loss: 0.298440 \tValidation Loss: 0.177132\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 30\n",
    "\n",
    "valid_loss_min = np.Inf # track change in validation loss\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()\n",
    "    for i in range(40):\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(trainD)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*trainD.size(0)\n",
    "        \n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    for i in range(40):\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(trainV)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average validation loss \n",
    "        valid_loss += loss.item()*trainV.size(0)\n",
    "    \n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/40\n",
    "    valid_loss = valid_loss/40\n",
    "        \n",
    "    # print training/validation statistics \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'model_cifar.pt')\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c9a86c",
   "metadata": {},
   "source": [
    "## Load the Model with the Lowest Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e37f8f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model_cifar.pt')) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3443626c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "torch.Size([18, 1, 64])\n",
      "torch.Size([18])\n"
     ]
    }
   ],
   "source": [
    "testD = torch_test\n",
    "target = class_te\n",
    "print(len(testD))\n",
    "print(testD.shape)\n",
    "print(target2.shape)\n",
    "classes = ['1','0']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c0138f",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9e413f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.226732\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# track test loss\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(2))\n",
    "class_total = list(0. for i in range(2))\n",
    "\n",
    "model.eval()\n",
    "# iterate over test data\n",
    "for j in range(18):\n",
    "    # move tensors to GPU if CUDA is available\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(testD)\n",
    "    # calculate the batch loss\n",
    "    loss = criterion(output, target)\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*testD.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)    \n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) \n",
    "    # calculate test accuracy for each object class\n",
    "    for i in range(18):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "# average test loss\n",
    "test_loss = test_loss/18\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "53bb6528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of     1: 100% (162/162)\n",
      "Test Accuracy of     0: 100% (162/162)\n",
      "\n",
      "Test Accuracy (Overall): 100% (324/324)\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed88f8e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
